{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29492750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luisf\\anaconda3\\Lib\\site-packages\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.pandas as ps\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa22c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "446efaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"consistency_test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e780d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----+------------+--------+----------+------------------+---------+--------+--------------+-----------+--------+--------------------+--------------+--------+------------+--------+------------+-----------------+------------+--------------+--------------+-------------+-------------+-----------+--------------+-----------+-----------+\n",
      "|user_id|churn| age|credit_score|deposits|withdrawal|purchases_partners|purchases|cc_taken|cc_recommended|cc_disliked|cc_liked|cc_application_begin|app_downloaded|web_user|app_web_user|ios_user|android_user|registered_phones|payment_type|waiting_4_loan|cancelled_loan|received_loan|rejected_loan|zodiac_sign|rewards_earned|reward_rate|is_referred|\n",
      "+-------+-----+----+------------+--------+----------+------------------+---------+--------+--------------+-----------+--------+--------------------+--------------+--------+------------+--------+------------+-----------------+------------+--------------+--------------+-------------+-------------+-----------+--------------+-----------+-----------+\n",
      "|      1|false|21.0|       577.0|      48|         4|                52|       45|       0|           245|          0|       0|                  22|          true|    true|        true|   false|        true|                2|Semi-Monthly|         false|         false|        false|        false|     Pisces|          56.0|       1.87|      false|\n",
      "|      8| true|31.0|       519.0|       0|         0|                 0|        0|       0|            49|          0|       0|                   2|          true|   false|       false|   false|        true|                0|   Bi-Weekly|         false|         false|        false|        false|      Virgo|          18.0|        0.6|       true|\n",
      "+-------+-----+----+------------+--------+----------+------------------+---------+--------+--------------+-----------+--------+--------------------+--------------+--------+------------+--------+------------+-----------------+------------+--------------+--------------+-------------+-------------+-----------+--------------+-----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fintech = spark.read.csv(\"clean_fintech.csv\", header = True, inferSchema=True)\n",
    "df_fintech.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159464c",
   "metadata": {},
   "source": [
    "## Transformations to perform:\n",
    "- Multiply all numeric columns * 2.\n",
    "- Delete the letter \"e\" from all str columns.\n",
    "- Set all bool variables to True.\n",
    "- Create 3 extra numeric columns:\n",
    "    - Mean of purchases.\n",
    "    - Median of age.\n",
    "    - Mean of credit_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5c7f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_2 = df_fintech.select('age','credit_score','purchases','zodiac_sign','payment_type','churn','cancelled_loan','received_loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f3920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_2 = df_fintech_2.withColumn(\"age\", df_fintech_2.age.cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_3 = df_fintech_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20499b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f49665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fintech_2 = df_fintech_2.withColumn(\"purchases_mean\", lit(df_fintech_2.select(mean('purchases')).collect()[0][0]))\\\n",
    "#              .withColumn(\"score_mean\", lit(df_fintech_2.select(mean('credit_score')).collect()[0][0]))\\\n",
    "#             .withColumn(\"age_median\", lit(df_fintech_2.select(median('age')).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf8cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_bool(df):\n",
    "    for c in [f.name for f in df.schema.fields if isinstance(f.dataType, BooleanType)]:\n",
    "        df = df.withColumn(c, lit(True))\n",
    "    return df\n",
    "\n",
    "def transform_str(df):\n",
    "    for c in [f.name for f in df.schema.fields if isinstance(f.dataType, StringType)]:\n",
    "        df = df.withColumn(c, regexp_replace(c, 'e', ''))\n",
    "    return df\n",
    "\n",
    "def transform_numeric(df):\n",
    "    for c in [f.name for f in df.schema.fields if isinstance (f.dataType, (IntegerType,DoubleType))]:\n",
    "        df = df.withColumn(c, df[c]*2)\n",
    "    return df\n",
    "\n",
    "def transform_extracols(df):\n",
    "    df = df.withColumn(\"purchases_mean\", lit(df.select(mean('purchases')).collect()[0][0]))\\\n",
    "             .withColumn(\"score_mean\", lit(df.select(mean('credit_score')).collect()[0][0]))\\\n",
    "            .withColumn(\"age_median\", lit(df.select(median('age')).collect()[0][0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd81f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_2 = df_fintech_2.transform(transform_str).transform(transform_numeric).transform(transform_bool).transform(transform_extracols)\n",
    "# result = (\n",
    "#    df.lazy()\n",
    "#    .pipe(add_position_column)\n",
    "#    .pipe(add_squad_number_column)\n",
    "#    .collect()\n",
    "#)\n",
    "#\n",
    "#result\n",
    "# https://typethepipe.com/vizs-and-tips/python-polars-pipe-function-to-one-more-columns/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc90674e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+---------+-----------+------------+-----+--------------+-------------+-----------------+------------------+----------+\n",
      "|age|     credit_score|purchases|zodiac_sign|payment_type|churn|cancelled_loan|received_loan|   purchases_mean|        score_mean|age_median|\n",
      "+---+-----------------+---------+-----------+------------+-----+--------------+-------------+-----------------+------------------+----------+\n",
      "| 42|           1154.0|       90|      Piscs| Smi-Monthly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 62|           1038.0|        0|      Virgo|     Bi-Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 52|1085.031199631591|        0|Sagittarius|        Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 66|           1116.0|        0|         Lo|     Bi-Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 52|           1118.0|        0|      Virgo|     Bi-Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 66|           1108.0|        4|  Capricorn| Smi-Monthly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "|108|           1002.0|        0|      Gmini|          na| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 54|            990.0|        0|         Lo|          na| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 56|           1000.0|        0|      Cancr|          na| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 54|1085.031199631591|        0|      Gmini|        Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 84|           1066.0|        0|      Cancr|     Bi-Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 50|           1064.0|        2|    Scorpio|     Bi-Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "|108|           1114.0|       86|    Scorpio|          na| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 76|           1180.0|        4|Sagittarius|          na| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 62|1085.031199631591|        0|    Scorpio|     Bi-Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 48|            988.0|        0|      Virgo|        Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 88|           1100.0|        0|      Libra|          na| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 60|           1124.0|       34|      Cancr|     Bi-Wkly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 82|           1218.0|        0|      Cancr|     Monthly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "| 72|           1002.0|        0|Sagittarius| Smi-Monthly| true|          true|         true|6.318724749692605|1085.1526258518454|      60.0|\n",
      "+---+-----------------+---------+-----------+------------+-----+--------------+-------------+-----------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fintech_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90942e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.DataFrame({\n",
    "'age':[42,62,52,66,52],\n",
    "'credit_score':[1154.0000,1038.0000,1085.031199631591,1116.0000,1118.0000],\n",
    "'purchases':[90,0,0,0,0],\n",
    "'zodiac_sign':['Piscs','Virgo','Sagittarius','Lo','Virgo'],\n",
    "'payment_type':['Smi-Monthly','Bi-Wkly','Wkly','Bi-Wkly','Bi-Wkly'],\n",
    "'churn':[True,True,True,True,True],\n",
    "'cancelled_loan':[True,True,True,True,True],\n",
    "'received_loan':[True,True,True,True,True],\n",
    "'purchases_mean':[6.318724749692605,6.318724749692605,6.318724749692605,6.318724749692605,6.318724749692605],\n",
    "'score_mean':[1085.1526258518454,1085.1526258518454,1085.1526258518454,1085.1526258518454,1085.1526258518454],\n",
    "'age_median':[60.0,60.0,60.0,60.0,60.0]\n",
    "})\n",
    "###\n",
    "pyspark_schema = StructType([\n",
    "StructField('age',IntegerType()),\n",
    "StructField('credit_score',DoubleType()),\n",
    "StructField('purchases',IntegerType()),\n",
    "StructField('zodiac_sign',StringType()),\n",
    "StructField('payment_type',StringType()),\n",
    "StructField('churn',BooleanType(),False),\n",
    "StructField('cancelled_loan',BooleanType(),False),\n",
    "StructField('received_loan',BooleanType(),False),\n",
    "StructField('purchases_mean',DoubleType(),False),\n",
    "StructField('score_mean',DoubleType(), False),\n",
    "StructField('age_median',DoubleType(),False)\n",
    "])\n",
    "\n",
    "df_expected = spark.createDataFrame(pandas_df, pyspark_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c62d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ff5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expected.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad01dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fintech_2.limit(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expected.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2232c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_orig.withColumn('hash_value', hash(*sorted(df_orig.columns))).select('hash_value').show(10)\n",
    "# df_expected.withColumn('hash_value', hash(*sorted(df_expected.columns))).select('hash_value').show(10)\n",
    "# Sum the hashes, see https://shortest.link/28YE\n",
    "# value = df.agg(F.sum('hash_value')).collect()[0][0]\n",
    "# https://stackoverflow.com/questions/52619099/pytest-assert-for-pyspark-dataframe-comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bca6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sorted(df_expected.collect()) == sorted(df_fintech_2.limit(5).collect()), \"Assertion failed\"\n",
    "print(\"Assertion completed succesfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c88b67d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a8ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transform df_orig inside the assert function.\n",
    "def assert_transform(df_orig):\n",
    "    \n",
    "    #transform orig\n",
    "    df_orig = df_orig.transform(transform_str).transform(transform_numeric).transform(transform_bool).transform(transform_extracols)\n",
    "    #expected df\n",
    "    pandas_df = pd.DataFrame({\n",
    "    'age':[42,62,52,66,52],\n",
    "    'credit_score':[1154.0000,1038.0000,1085.031199631591,1116.0000,1118.0000],\n",
    "    'purchases':[90,0,0,0,0],\n",
    "    'zodiac_sign':['Piscs','Virgo','Sagittarius','Lo','Virgo'],\n",
    "    'payment_type':['Smi-Monthly','Bi-Wkly','Wkly','Bi-Wkly','Bi-Wkly'],\n",
    "    'churn':[True,True,True,True,True],\n",
    "    'cancelled_loan':[True,True,True,True,True],\n",
    "    'received_loan':[True,True,True,True,True],\n",
    "    'purchases_mean':[6.318724749692605,6.318724749692605,6.318724749692605,6.318724749692605,6.318724749692605],\n",
    "    'score_mean':[1085.1526258518454,1085.1526258518454,1085.1526258518454,1085.1526258518454,1085.1526258518454],\n",
    "    'age_median':[60.0,60.0,60.0,60.0,60.0]\n",
    "    })\n",
    "    ###\n",
    "    pyspark_schema = StructType([\n",
    "    StructField('age',IntegerType()),\n",
    "    StructField('credit_score',DoubleType()),\n",
    "    StructField('purchases',IntegerType()),\n",
    "    StructField('zodiac_sign',StringType()),\n",
    "    StructField('payment_type',StringType()),\n",
    "    StructField('churn',BooleanType(),False),\n",
    "    StructField('cancelled_loan',BooleanType(),False),\n",
    "    StructField('received_loan',BooleanType(),False),\n",
    "    StructField('purchases_mean',DoubleType(),False),\n",
    "    StructField('score_mean',DoubleType(), False),\n",
    "    StructField('age_median',DoubleType(),False)\n",
    "    ])\n",
    "\n",
    "    df_expected = spark.createDataFrame(pandas_df, pyspark_schema)\n",
    "    df_orig.show()\n",
    "    assert sorted(df_expected.collect()) == sorted(df_orig.limit(5).collect()), \"Assertion failed\"\n",
    "    print(\"Assertion completed succesfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faae28fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+---------+-----------+------------+-----+--------------+-------------+--------------+------------------+----------+\n",
      "|age|     credit_score|purchases|zodiac_sign|payment_type|churn|cancelled_loan|received_loan|purchases_mean|        score_mean|age_median|\n",
      "+---+-----------------+---------+-----------+------------+-----+--------------+-------------+--------------+------------------+----------+\n",
      "| 42|           1154.0|       90|      Piscs| Smi-Monthly| true|          true|         true|          18.0|1102.2062399263182|      52.0|\n",
      "| 62|           1038.0|        0|      Virgo|     Bi-Wkly| true|          true|         true|          18.0|1102.2062399263182|      52.0|\n",
      "| 52|1085.031199631591|        0|Sagittarius|        Wkly| true|          true|         true|          18.0|1102.2062399263182|      52.0|\n",
      "| 66|           1116.0|        0|         Lo|     Bi-Wkly| true|          true|         true|          18.0|1102.2062399263182|      52.0|\n",
      "| 52|           1118.0|        0|      Virgo|     Bi-Wkly| true|          true|         true|          18.0|1102.2062399263182|      52.0|\n",
      "+---+-----------------+---------+-----------+------------+-----+--------------+-------------+--------------+------------------+----------+\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Assertion failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m assert_transform(df_fintech_2\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m, in \u001b[0;36massert_transform\u001b[1;34m(df_orig)\u001b[0m\n\u001b[0;32m     35\u001b[0m df_expected \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(pandas_df, pyspark_schema)\n\u001b[0;32m     36\u001b[0m df_orig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(df_expected\u001b[38;5;241m.\u001b[39mcollect()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28msorted\u001b[39m(df_orig\u001b[38;5;241m.\u001b[39mcollect()), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssertion failed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssertion completed succesfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Assertion failed"
     ]
    }
   ],
   "source": [
    "assert_transform(df_fintech_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a25eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# para la versi√≥n 3.5.0 en adelante: \n",
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.testing.assertDataFrameEqual.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
